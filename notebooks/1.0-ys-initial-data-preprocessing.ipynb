{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "ps = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTweets = pd.read_csv('../data/raw/tweets.csv', encoding='utf-8', low_memory=False)\n",
    "dfTweetsSpam = pd.read_csv('../data/raw/tweets_spam.csv', encoding='utf-8', low_memory=False)\n",
    "dfTweetsUsers = pd.read_csv('../data/raw/users.csv', encoding='utf-8', low_memory=False)\n",
    "dfTweetsSpamUsers = pd.read_csv('../data/raw/users_spam.csv', encoding='utf-8', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the number of tweets each user in dfTweetsSpamUsers has in dfTweetsSpam\n",
    "dfTweetsSpamUsers['numTweets'] = dfTweetsSpamUsers['id'].apply(lambda x: dfTweetsSpam[dfTweetsSpam['user_id'] == x].shape[0])\n",
    "#get the number of tweets each user in dfTweetsUsers has in dfTweets\n",
    "dfTweetsUsers['numTweets'] = dfTweetsUsers['id'].apply(lambda x: dfTweets[dfTweets['user_id'] == x].shape[0])\n",
    "#remove users in dfTweetsUsers that have 0 numTweets\n",
    "dfTweetsUsers = dfTweetsUsers[dfTweetsUsers['numTweets'] != 0]\n",
    "#remove users in dfTweetsSpamUsers that have 0 numTweets\n",
    "dfTweetsSpamUsers = dfTweetsSpamUsers[dfTweetsSpamUsers['numTweets'] != 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove tweets in dfTweetsSpam that do not have a user in dfTweetsSpamUsers\n",
    "dfTweetsSpam = dfTweetsSpam[dfTweetsSpam['user_id'].isin(dfTweetsSpamUsers['id'])]\n",
    "#remove tweets in dfTweets that do not have a user in dfTweetsUsers\n",
    "dfTweets = dfTweets[dfTweets['user_id'].isin(dfTweetsUsers['id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get users in dfTweets with more than 1000 tweets\n",
    "users_with_more_than_1000_tweets = dfTweetsUsers[dfTweetsUsers['numTweets'] > 1000]['id']\n",
    "\n",
    "# limit the number of tweets to 1000 for each user in dfTweets that has more than 1000 tweets\n",
    "for user_id in users_with_more_than_1000_tweets:\n",
    "    user_tweets = dfTweets[dfTweets['user_id'] == user_id]\n",
    "    if user_tweets.shape[0] > 1000:\n",
    "        dfTweets.drop(user_tweets.sort_values(by='created_at', ascending=False).iloc[1000:].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label spam tweets & users\n",
    "dfTweetsSpam['label'] = 1\n",
    "dfTweetsSpamUsers['label'] = 1\n",
    "#label non-spam tweets & users\n",
    "dfTweets['label'] = 0\n",
    "dfTweetsUsers['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the spam and non-spam tweets into one dataframe\n",
    "dfTweets = pd.concat([dfTweets, dfTweetsSpam], ignore_index=True)\n",
    "#combine the spam and non-spam users into one dataframe\n",
    "dfTweetsUsers = pd.concat([dfTweetsUsers, dfTweetsSpamUsers], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix in_reply_to_status_id in dfTweets: If the value is not 0, replace it with 1 & rename column\n",
    "dfTweets['is_reply'] = dfTweets['in_reply_to_status_id'].apply(lambda x: 1 if x != 0 else 0)\n",
    "dfTweets = dfTweets.drop('in_reply_to_status_id', axis=1)\n",
    "#fix place in dfTweets: If the value is NaN replace with 0, else 1\n",
    "dfTweets['place'] = dfTweets['place'].apply(lambda x: 0 if pd.isna(x) else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "userFeatures=['label','id','name', 'screen_name','followers_count', 'friends_count',\n",
    "              'favourites_count','listed_count','location','default_profile',\n",
    "              'geo_enabled','verified','description']\n",
    "tweetFeatures = ['label','user_id','text','is_reply','place', 'retweet_count', 'favorite_count', 'possibly_sensitive', 'num_hashtags', 'num_mentions', 'num_urls',]\n",
    "\n",
    "#feature selection\n",
    "dfTweetsUsers = dfTweetsUsers[userFeatures]\n",
    "dfTweets = dfTweets[tweetFeatures]\n",
    "#rename columns to capitalize first letter\n",
    "dfTweetsUsers.columns = [x.capitalize() for x in dfTweetsUsers.columns]\n",
    "dfTweets.columns = [x.capitalize() for x in dfTweets.columns]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate text by words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# split text column into words\n",
    "words = dfTweets['Text'].str.split(expand=True).stack()\n",
    "\n",
    "# count word frequencies with Counter object\n",
    "wordFreq = Counter(word.translate(str.maketrans('', '', string.punctuation)).strip(\"…\").lower() \n",
    "                   for word in words \n",
    "                   if \"http\" not in word and \"@\" not in word and \"#\" not in word and not word.startswith(\"www\"))\n",
    "\n",
    "# filter out words that appear less than 100 times with dictionary comprehension\n",
    "wordFreq = {word:freq for word, freq in wordFreq.items() if freq >= 100}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_word(word):\n",
    "    #remove punctuation, make lowercase & stem\n",
    "    return ps.stem(word.translate(str.maketrans('', '', string.punctuation)).strip(\"…\").lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the number of times each word appears in the text of each tweet for each user\n",
    "freq_df = pd.DataFrame(columns=['Id'] + list(wordFreq.keys()))\n",
    "\n",
    "for index, row in dfTweetsUsers.iterrows():\n",
    "    userTweets = dfTweets[dfTweets['User_id'] == row['Id']]\n",
    "    words = userTweets['Text'].str.split(expand=True).stack()\n",
    "    wordFreqTweet = Counter(standardize_word(word) for word in words if \"http\" not in word and \"@\" not in word and \"#\" not in word and not word.startswith(\"www\"))\n",
    "    freq_df.loc[index] = [row['Id']] + [wordFreqTweet[word] for word in wordFreq.keys()]\n",
    "\n",
    "#merge\n",
    "dfTweetsUsers = pd.merge(dfTweetsUsers, freq_df, on='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each user, get the total number of words in all their tweets\n",
    "dfTweetsUsers['totalWords'] = dfTweetsUsers[wordFreq.keys()].sum(axis=1)\n",
    "#divide each word count by the total number of words in all the user's tweets\n",
    "for word in wordFreq.keys():\n",
    "    dfTweetsUsers[word] = dfTweetsUsers[word].div(dfTweetsUsers['totalWords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTweets.fillna(0, inplace=True)\n",
    "#fill the Default_profile,Verified and Geo_enabled columns with 0 if NaN\n",
    "dfTweetsUsers['Default_profile'].fillna(0, inplace=True)\n",
    "dfTweetsUsers['Geo_enabled'].fillna(0, inplace=True)\n",
    "dfTweetsUsers['Verified'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frost\\AppData\\Local\\Temp\\ipykernel_9788\\2146919341.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfTweetsUsers['Total_retweet_count'] = dfTweetsUsers['Id'].apply(lambda x: dfTweets[dfTweets['User_id'] == x]['Retweet_count'].sum())\n",
      "C:\\Users\\frost\\AppData\\Local\\Temp\\ipykernel_9788\\2146919341.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfTweetsUsers['Total_favorite_count'] = dfTweetsUsers['Id'].apply(lambda x: dfTweets[dfTweets['User_id'] == x]['Favorite_count'].sum())\n",
      "C:\\Users\\frost\\AppData\\Local\\Temp\\ipykernel_9788\\2146919341.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfTweetsUsers['Total_mentions'] = dfTweetsUsers['Id'].apply(lambda x: dfTweets[dfTweets['User_id'] == x]['Num_mentions'].sum())\n",
      "C:\\Users\\frost\\AppData\\Local\\Temp\\ipykernel_9788\\2146919341.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfTweetsUsers['Total_urls'] = dfTweetsUsers['Id'].apply(lambda x: dfTweets[dfTweets['User_id'] == x]['Num_urls'].sum())\n"
     ]
    }
   ],
   "source": [
    "dfTweetsUsers['Total_retweet_count'] = dfTweetsUsers['Id'].apply(lambda x: dfTweets[dfTweets['User_id'] == x]['Retweet_count'].sum())\n",
    "dfTweetsUsers['Total_favorite_count'] = dfTweetsUsers['Id'].apply(lambda x: dfTweets[dfTweets['User_id'] == x]['Favorite_count'].sum())\n",
    "dfTweetsUsers['Total_mentions'] = dfTweetsUsers['Id'].apply(lambda x: dfTweets[dfTweets['User_id'] == x]['Num_mentions'].sum())\n",
    "dfTweetsUsers['Total_urls'] = dfTweetsUsers['Id'].apply(lambda x: dfTweets[dfTweets['User_id'] == x]['Num_urls'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTweetsUsers.to_csv('../data/processed/users.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac80ca7cf72d6103323b6006f0c22121360dd4bb4896d7ab6811c132cbad5cf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
