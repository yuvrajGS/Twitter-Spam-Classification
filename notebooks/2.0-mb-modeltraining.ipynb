{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to suppress all FutureWarnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# for data manipulation\n",
    "import pandas as pd, numpy as np, random\n",
    "\n",
    "#models to run\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#train_test_split\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "#mean absolute error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#sklearn metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score, r2_score, accuracy_score, roc_auc_score\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "random.seed(RANDOM_STATE)\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import layers\n",
    "#for graphs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Dataset\n",
    "#users = pd.read_csv('data/processed/users.csv', encoding='utf-8', low_memory=False)\n",
    "users = pd.read_csv('../data/processed/users.csv', encoding='utf-8', low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.sample(frac=1, random_state=RANDOM_STATE).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = users.drop(['Name','Screen_name','Label','Description','Id','Location'], axis=1)\n",
    "\n",
    "y = users['Label']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop these columns from X: ['forget', 'cuando', 'color', 'di', 'strong', 'save', 'son', 'over', 'año', 'hand', 'march', 'make', 'mucho', 'share', 'qué', 'take', 'war', 'apart', 'foi', 'market', 'still', 'so', 'totalWords', 'been', 'okay', 'hoy', 'Followers_count', 'bad', 'eso', 'free', '5', 'san', 'sleep', 'twitter', 'Geo_enabled', 'rt', 'wrong', '2013', 'tonight', 'last', 'can', 'fuck', 'Friends_count', 'light', 'say', 'noch', 'be', 'down', 'Total_urls', 'oh', 'we', 'sure', '—', 'tomorrow', 'talk', 'where', 'team', '2014', 'around', 'time', 'doesnt', 'Total_mentions', 'Favourites_count', 'it', 'watch', 'could', 'need', 'off', 'ever', 'birthday', 'right', 'world', 'better', 'know', 'thing', 'an', 'he', 'miss', 'had', 'keep', 'let', 'happen', 'did', 'next', 'us', 'thank', 'stop', 'after', 'tell', 'call', 'same', 'their', 'wait', 'back', 'amp', 'Total_favorite_count', 'hate', 'Total_retweet_count', 'hope', 'even']\n",
    "\n",
    "X = X.drop(['forget', 'cuando', 'color', 'di', 'strong', 'save', 'son', 'over', 'año', 'hand', 'march', 'make', 'mucho', 'share', 'qué', 'take', 'war', 'apart', 'foi', 'market', 'still', 'so', 'totalWords', 'been', 'okay', 'hoy', 'Followers_count', 'bad', 'eso', 'free', '5', 'san', 'sleep', 'twitter', 'Geo_enabled', 'rt', 'wrong', '2013', 'tonight', 'last', 'can', 'fuck', 'Friends_count', 'light', 'say', 'noch', 'be', 'down', 'Total_urls', 'oh', 'we', 'sure', '—', 'tomorrow', 'talk', 'where', 'team', '2014', 'around', 'time', 'doesnt', 'Total_mentions','Favourites_count', 'it', 'watch', 'could', 'need', 'off', 'ever', 'birthday', 'right', 'world', 'better', 'know', 'thing', 'an', 'he', 'miss', 'had', 'keep', 'let', 'happen', 'did', 'next', 'us', 'thank', 'stop', 'after', 'tell', 'call', 'same', 'their', 'wait', 'back', 'amp', 'Total_favorite_count', 'hate', 'Total_retweet_count', 'hope', 'even'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.drop(['berkalikali', 'enterprise', 'passenger', 'km', 'raiders', 'hater', 'aos', '79', 'chin', 'aim', 'beliefs', 'healing', 'rains', 'handed', 'hoo', 'woo', 'edit', 'bee', 'darling', 'whatsapp', 'downloaded', 'dot', 'professor', 'clouds', 'counts', 'study', 'wit', 'sec', 'arrive', '1b', 'potter', 'harry', 'jk', 'theyve', 'beware', 'rice', 'brb', 'crown', 'den', 'corrupt', 'obamas', 'restart', 'district', 'chris', 'stomach', 'olicity', 'tale', 'explode', 'anti', 'vice', 'karma', 'kindness', 'queen', 'caramel', 'kaibigan', 'discovered', 'officer', 'yemen', 'split', 'toll', 'nepal', 'revolution', 'chill', 'policies', 'mysterious', 'buddies', 'villa', 'roommate', 'idk', 'medal', 'md', 'management', 'opportunity', 'daniel', 'manage', 'relevant', 'followers', 'microsoft', 'poverty', 'hosting', 'stress', 'percent', 'massage', 'weekly', 'oz', 'hanggang', '2k', 'function', 'thankyou', 'tay', 'ohhhh', 'disrespectful', 'training', 'asses', 'hated', 'spectacular', 'valid', 'guilty', 'proven', 'unnecessary'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.drop(['fridge', 'tiene', 'equipo', 'olympic', 'lab', 'backed', 'tennis', 'murray', 'yesterdays', 'duke', 'follower', 'happiest', 'sé', 'rated', 'clever', 'restaurants', 'visits', 'teachers', 'mais', 'ex', 'sessions', 'kentucky', 'located', 'islands', 'greece', 'discovery', 'gr8', 'toys', 'tres', 'muy', 'statistics', 'pros', 'mens', 'waves', 'deliver', 'spill', 'giants', 'joined', 'reported', 'carbon', 'api', 'petition', 'thrown', 'dump', 'forecast', 'cameron', 'palace', 'nonsense', 'champions', 'att', 'properly', 'luis', 'sao', 'problema', 'resort', 'importante', 'featuring', 'sponsors', 'xp', 'focused', 'title', 'aggressive', 'passive', 'cuts', 'jimmy', 'rooney', 'photographers', 'afghanistan', 'mentorship', 'cotton', 'vids', 'agenda', 'neymar', 'intelligent', 'attend', 'expecting', 'regret', 'vez', 'cada', 'consumers', 'explains', 'commission', 'handling', 'elite', 'according', 'spin', 'bees', 'yard', 'oscar', 'require', 'hobby', 'facing', 'sides', 'keen', 'rail', 'uploaded', 'sai', 'period', 'triple', 'messenger'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.drop(['garcia', 'kim', 'boxes', 'aug', 'lesson', 'segment', 'warns', '120', 'trading', 'est', '19th', 'puppies', 'kardashian', 'lg', 'pun', 'releasing', 'genuinely', 'rs', 'halo', 'listed', 'cos', '54', 'wallet', 'consumer', 'visa', 'wrist', 'fifth', 'ceremony', 'colors', 'autocorrect', 'routine', 'cap', 'decline', 'funds', 'airline', 'depressed', 'rio', 'leo', 'mag', 'headline', 'madrid', 'picks', 'indonesia', 'lawyers', 'anyways', 'flame', 'turtle', 'andre', 'brazil', 'espn', 'independence', 'messi', 'saves', 'mexico', 'nov', 'scotland', 'includes', 'kit', 'versus', 'invest', 'innovation', 'fifa', 'dropbox', 'pakistani', 'solutions', 'ibm', 'cheat', 'apply', 'locker', 'unfortunately', 'passengers', 'opens', 'nexus', 'developers', 'travis', 'volume', 'asia', 'december', 'emojis', 'hundred', 'cooler', 'indians', 'mere', 'answering', 'washington', 'brick', 'promises', 'ranked', 'ch', 'channels', 'modi', 'bhai', 'ebay', 'ranking', 'yang', 'ministry', 'hahahah', 'charged', 'myspace', '200',],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, X, y, n_neighbors=5, test_size=0.2, random_state=42):\n",
    "        \"\"\"\n",
    "        Initialize the KNN classifier.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "            X (pandas.DataFrame): The feature matrix of shape (n_samples, n_features).\n",
    "            y (pandas.Series): The target vector of shape (n_samples,).\n",
    "            n_neighbors (int, optional): The number of nearest neighbors to use in classification. Defaults to 5.\n",
    "            test_size (float, optional): The proportion of samples to use for testing. Defaults to 0.2.\n",
    "            random_state (int, optional): The random state to use for splitting the data. Defaults to 42.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.model = None\n",
    "        self.best_params = None\n",
    "        self.best_score = None\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Predict the target values for the test data.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        None\n",
    "\n",
    "        Returns:\n",
    "        -----------\n",
    "            numpy.ndarray: The predicted target values of shape (n_samples,)\n",
    "        \"\"\"\n",
    "        X_train, X_test, y_train, self.y_test = train_test_split(self.X, self.y, test_size=self.test_size, random_state=self.random_state,stratify=self.y)\n",
    "        self.model.fit(X_train, y_train)\n",
    "        return self.model.predict(X_test)\n",
    "       \n",
    "    \n",
    "    def score(self):\n",
    "        \"\"\"\n",
    "        Calculate the accuracy score and classification report for the KNN model.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        None\n",
    "\n",
    "        Returns:\n",
    "        -----------\n",
    "        accuracy score: The ratio of the correctly predicted observations to the total observations.\n",
    "        \n",
    "        classification report: A text report of the main classification metrics such as precision, recall, f1-score and support for each class.\n",
    "        \"\"\"\n",
    "\n",
    "        y_pred = self.predict()\n",
    "        return accuracy_score(self.y_test, y_pred), classification_report(self.y_test, y_pred)\n",
    "        \n",
    "    \n",
    "\n",
    "    def grid_search(self, param_grid):\n",
    "        \"\"\"\n",
    "        Perform a grid search to find the best hyperparameters for the KNN model.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "            param_grid (dict): A dictionary of hyperparameters to test.\n",
    "\n",
    "        Returns:\n",
    "        -----------\n",
    "            None\n",
    "        \"\"\"\n",
    "        #5 fold cross validation + accuracy evaluation metric\n",
    "        grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "        self.best_params = grid_search.fit(self.X,self.y).best_params_\n",
    "        print(self.best_params)\n",
    "        #metric -> euclidean, manhattan, minkowski, chebyshev\n",
    "        self.model = KNeighborsClassifier(n_neighbors=self.best_params['n_neighbors'], metric=self.best_params['metric'])\n",
    "        #holds the highest accuracy achieved during the grid search\n",
    "        self.best_score = grid_search.fit(self.X,self.y).best_score_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': 'manhattan', 'n_neighbors': 20}\n",
      "The accuracy achieved by knn model: 0.8561151079136691\n",
      "############################################################\n",
      "The classification report of knn model: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       217\n",
      "           1       0.99      0.70      0.82       200\n",
      "\n",
      "    accuracy                           0.86       417\n",
      "   macro avg       0.89      0.85      0.85       417\n",
      "weighted avg       0.88      0.86      0.85       417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#testing KNN\n",
    "fit_knn = KNN(X, y, n_neighbors=5, test_size=0.2, random_state=42)\n",
    "fit_knn.grid_search({'n_neighbors': [20], 'metric': ['manhattan']})\n",
    "pred_knn = fit_knn.predict()\n",
    "accuracy_knn, classification_report_knn = fit_knn.score()\n",
    "print(\"The accuracy achieved by knn model:\", accuracy_knn) \n",
    "print('#'*60)\n",
    "print(\"The classification report of knn model: \\n\", classification_report_knn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, X, y, random_state=RANDOM_STATE):\n",
    "        \"\"\"Initializes the RandomForest class with the input features X and target variable y,\n",
    "        and the random state used for reproducibility.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : pandas.DataFrame\n",
    "            The input feature matrix of shape (n_samples, n_features).\n",
    "        y : pandas.Series\n",
    "            The target variable of shape (n_samples,).\n",
    "        random_state : int, default=RANDOM_STATE, which is 42\n",
    "            The seed value for random number generator used to split the data.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        None\"\"\"\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.random_state = random_state\n",
    "        self.model = None\n",
    "        self.best_params = {} \n",
    "        self.best_score = 0 \n",
    "        \n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"Predicts the target variable of the test data using the trained random forest model.\n",
    "        Returns the predicted target variable values.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        None\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        numpy.ndarray: The predicted target variable values\n",
    "        \n",
    "        \"\"\"\n",
    "        #initalize self.model\n",
    "        X_train, X_test, y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.2, random_state=self.random_state,stratify=self.y)\n",
    "        self.model.fit(X_train, y_train)\n",
    "        return self.model.predict(X_test)\n",
    "    \n",
    "    def score(self):\n",
    "        \"\"\"Computes the accuracy score and classification report for the predicted target variable and the actual test target variable.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        None\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        accuracy score: The ratio of the correctly predicted observations to the total observations.\n",
    "        \n",
    "        classification report: A text report of the main classification metrics such as precision, recall, f1-score and support for each class.\"\"\"\n",
    "        \n",
    "        y_pred = self.predict()\n",
    "        return accuracy_score(self.y_test, y_pred), classification_report(self.y_test, y_pred)\n",
    "    \n",
    "    def grid_search(self, param_grid):\n",
    "        \"\"\"Performs a grid search to find the best hyperparameters for the random forest model.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "            param_grid (dict): A dictionary of hyperparameters to test.\n",
    "\n",
    "        Returns:\n",
    "        -----------\n",
    "            None\n",
    "        \"\"\"\n",
    "        # 'max_depth': [7,9], \n",
    "        # 'min_samples_split': [5,7],\n",
    "        # 'max_leaf_nodes': [10,25],\n",
    "        # 'n_estimators': [39,40,41]\n",
    "        #5 fold cross validation + accuracy evaluation metric\n",
    "        grid_search = GridSearchCV(RandomForestClassifier(random_state=self.random_state), param_grid, cv=5, scoring='accuracy')\n",
    "        self.best_params = grid_search.fit(self.X,self.y).best_params_\n",
    "        print(self.best_params)\n",
    "        self.model = RandomForestClassifier(n_estimators=self.best_params['n_estimators'])#, max_depth=self.best_params['max_depth'], random_state=self.random_state)\n",
    "        self.best_score = grid_search.fit(self.X,self.y).best_score_\n",
    "\n",
    "    def plot_feature_importance(self, top=100):\n",
    "        \"\"\"Plots a horizontal bar chart of the top (by default 10) important features in the random forest model.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        top: The number of top important features to display. Default is 10.\n",
    "\n",
    "        Returns: \n",
    "        -----------\n",
    "        None\"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        importances = self.model.feature_importances_\n",
    "        indices = np.argsort(importances)\n",
    "        plt.title(\"Feature Importance\")\n",
    "        #note: [-top:] -> last element to the top element\n",
    "        #[importances[i] for i in indices[-top:] top important features\n",
    "        #self.X.columns[i] for i in indices[-top:] column names\n",
    "        sns.barplot(x=[importances[i] for i in indices[-top:]][::-1], y=[self.X.columns[i] for i in indices[-top:]][::-1], orient='h')\n",
    "        plt.yticks(range(top), [self.X.columns[i] for i in indices[-top:]])\n",
    "        plt.xlabel(\"Relative Importance\")\n",
    "        plt.draw()\n",
    "        #get the 50 features with the least importance\n",
    "        least_important = [self.X.columns[i] for i in indices[:top]]\n",
    "        #print\n",
    "        print(least_important)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 40}\n",
      "The accuracy achieved by random forest model: 0.9688249400479616\n",
      "############################################################\n",
      "The classification report of random forest model: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       217\n",
      "           1       0.97      0.96      0.97       200\n",
      "\n",
      "    accuracy                           0.97       417\n",
      "   macro avg       0.97      0.97      0.97       417\n",
      "weighted avg       0.97      0.97      0.97       417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#testing KNN\n",
    "fit_rf = RandomForest(X, y, random_state=42)\n",
    "fit_rf.grid_search({'n_estimators': [40]})\n",
    "pred_rf = fit_rf.predict()\n",
    "accuracy_rf, classification_report_rf = fit_rf.score()\n",
    "print(\"The accuracy achieved by random forest model:\", accuracy_rf)\n",
    "print('#'*60)\n",
    "print(\"The classification report of random forest model: \\n\", classification_report_rf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNetworkModel:\n",
    "    def __init__(self, X, y, random_state=RANDOM_STATE):\n",
    "        \"\"\"Initializes the NeuralNetworkModel class with the input features X and target variable y,\n",
    "        and the random state used for reproducibility.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : pandas.DataFrame\n",
    "            The input feature matrix of shape (n_samples, n_features).\n",
    "        y : pandas.Series\n",
    "            The target variable of shape (n_samples,).\n",
    "        random_state : int, default=RANDOM_STATE, which is 42\n",
    "            The seed value for random number generator used to split the data.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        None\"\"\"\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.random_state = random_state\n",
    "        self.model = None\n",
    "        self.history = None\n",
    "        self.epochs = 100\n",
    "        self.batch_size = 32\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"Builds and compiles the neural network model using the input features X.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        None\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        None\"\"\"\n",
    "        \n",
    "        # Define the model\n",
    "        self.model = keras.Sequential([\n",
    "            layers.Dense(64, activation='relu', input_shape=[self.X.shape[1]]),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        \n",
    "        # Compile the model\n",
    "        self.model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "    def fit(self):\n",
    "        \"\"\"Trains the neural network model on the input features X and target variable y.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X_train : pandas.DataFrame\n",
    "            The input feature matrix of shape (n_samples, n_features) for training.\n",
    "        y_train : pandas.Series\n",
    "            The target variable of shape (n_samples,) for training.\n",
    "        X_val : pandas.DataFrame\n",
    "            The input feature matrix of shape (n_samples, n_features) for validation.\n",
    "        y_val : pandas.Series\n",
    "            The target variable of shape (n_samples,) for validation.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        float: The accuracy score of the trained model on the validation data.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Fit the model\n",
    "        self.model.fit(\n",
    "            self.X_train, self.y_train,\n",
    "            epochs=self.epochs, batch_size=self.batch_size,\n",
    "            validation_data=(self.X_test, self.y_test),\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Compute the accuracy score\n",
    "        y_pred = (self.model.predict(self.X_test)).astype(\"int32\")\n",
    "        score = accuracy_score(self.y_test, y_pred)\n",
    "        \n",
    "        return score\n",
    "\n",
    "        \n",
    "    def predict(self):\n",
    "        \"\"\"Predicts the target variable of the test data using the trained neural network model.\n",
    "        Returns the predicted target variable values.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        None\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        numpy.ndarray: The predicted target variable values\n",
    "        \"\"\"\n",
    "        \n",
    "        return (self.model.predict(self.X_test)).astype(\"int32\")\n",
    "    \n",
    "    def score(self):\n",
    "        \"\"\"Computes the accuracy score and classification report for the predicted target variable and the actual test target variable.\n",
    "\n",
    "        Parameters:\n",
    "        X_test: array-like, shape (n_samples, n_features)\n",
    "            The test input samples.\n",
    "        y_test: array-like, shape (n_samples,)\n",
    "            The true target values for X_test.\n",
    "\n",
    "        Returns:\n",
    "        accuracy: float\n",
    "            The accuracy score of the model on the test data.\n",
    "        classification_report: str\n",
    "            A text report of the main classification metrics such as precision, recall, f1-score and support for each class.\n",
    "        \"\"\"\n",
    "        y_pred = self.predict()\n",
    "        accuracy = accuracy_score(self.y_test, y_pred)\n",
    "        classificationReport = classification_report(self.y_test, y_pred)\n",
    "        return accuracy, classificationReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 9ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "The accuracy achieved by neural network model: 0.762589928057554\n",
      "############################################################\n",
      "The classification report of neural network model: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      1.00      0.81       216\n",
      "           1       0.99      0.51      0.68       201\n",
      "\n",
      "    accuracy                           0.76       417\n",
      "   macro avg       0.84      0.75      0.74       417\n",
      "weighted avg       0.83      0.76      0.75       417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "\n",
    "\n",
    "# Create an instance of the NeuralNetworkModel class\n",
    "fit_nn = NeuralNetworkModel(X, y, random_state=42)\n",
    "\n",
    "# Build the neural network model\n",
    "fit_nn.build_model()\n",
    "\n",
    "# Fit the model\n",
    "fit_nn.fit()\n",
    "\n",
    "# Predict the target variable of the test data\n",
    "pred_nn = fit_nn.predict()\n",
    "\n",
    "# Compute the accuracy score and classification report\n",
    "accuracy_nn, classification_report_nn = fit_nn.score()\n",
    "print(\"The accuracy achieved by neural network model:\", accuracy_nn)\n",
    "print('#'*60)\n",
    "print(\"The classification report of neural network model: \\n\", classification_report_nn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
